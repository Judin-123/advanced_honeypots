
# ML Training Report - Adaptive Honeypot System
Generated: 2025-09-22 11:20:27

## Dataset Summary
- CICIDS 2017 (Synthetic): Network flow features for attack detection
- Honeypot Dataset: Behavioral features for threat classification
- Combined training samples: 10 features

## Model Performance Summary

### Isolation Forest
- Accuracy: 0.590
- AUC Score: 0.507
- Precision: 0.432
- Recall: 0.105
- F1-Score: 0.169

### Xgboost
- Accuracy: 0.819
- AUC Score: 0.815
- Precision: 0.760
- Recall: 0.796
- F1-Score: 0.778

### Random Forest
- Accuracy: 0.827
- AUC Score: 0.834
- Precision: 0.739
- Recall: 0.872
- F1-Score: 0.800

### Neural Network
- Accuracy: 0.807
- AUC Score: 0.804
- Precision: 0.743
- Recall: 0.786
- F1-Score: 0.764

## Feature Engineering
The following features were extracted and used for training:
- flow_rate
- packet_size_mean
- packet_size_std
- timing_variance
- protocol_diversity
- size_entropy
- temporal_pattern
- anomaly_score
- burst_pattern
- regularity_score

## Model Files
All trained models have been saved to the 'trained_models/' directory:
- isolation_forest_model.pkl
- xgboost_model.pkl
- random_forest_model.pkl
- neural_network_model.pkl

## Usage
Load models using:
```python
import joblib
model = joblib.load('trained_models/xgboost_model.pkl')
scaler = joblib.load('trained_models/scaler.pkl')
```

## Recommendations
1. XGBoost typically provides the best balance of accuracy and interpretability
2. Isolation Forest is excellent for detecting novel attack patterns
3. Ensemble methods combining multiple models often yield superior results
4. Regular retraining with new honeypot data is recommended

Generated by Adaptive Honeypot ML Training Pipeline
